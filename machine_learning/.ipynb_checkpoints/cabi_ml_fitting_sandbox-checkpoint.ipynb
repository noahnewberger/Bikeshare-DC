{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CaBi ML fitting sandbox\n",
    "\n",
    "5/27: Sandbox created from copying the Champion nb.\n",
    "* At this point, I've found that dc_pop is more predictive than the dock/station variables and cabi_active_members_day_key and daylight_hours is more predictive than cabi_active_members_monthly\n",
    "* Now we can try tweaking other things\n",
    "* After changing the cross-validation to include shuffling, everything performs better, including Ridge\n",
    "  * This is probably a good thing? It shows that the model is more generalizable, and that any issues we had in CV earlier were because the non-shuffled folds weren't each representative of the full sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Data load, shaping, and split\n",
    "* Read in data from AWS\n",
    "  * Check for high pairwise correlation\n",
    "* Encode time variable (day_of_year) as cyclical\n",
    "* Split into Xtrain, Xtest, ytrain, ytest based on date\n",
    "  * Specify feature and target columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 2780 instances and 28 features\n"
     ]
    }
   ],
   "source": [
    "# Read in data from AWS\n",
    "\n",
    "from util_functions import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "set_env_path()\n",
    "conn, cur = aws_connect()\n",
    "\n",
    "# fullquery contains all of the variables within consideration\n",
    "\n",
    "fullquery = \"\"\"\n",
    "SELECT \n",
    "EXTRACT(DOY FROM date) as day_of_year,\n",
    "date,\n",
    "daylight_hours,\n",
    "apparenttemperaturehigh,\n",
    "apparenttemperaturelow,\n",
    "cloudcover,\n",
    "dewpoint,\n",
    "humidity,\n",
    "precipaccumulation,\n",
    "precipintensitymax,\n",
    "precipprobability,\n",
    "rain,\n",
    "snow,\n",
    "visibility,\n",
    "windspeed,\n",
    "us_holiday,\n",
    "nats_single,\n",
    "nats_double,\n",
    "dc_bike_event,\n",
    "dc_pop,\n",
    "cabi_bikes_avail,\n",
    "cabi_stations_alx,\n",
    "cabi_stations_arl,\n",
    "cabi_stations_ffx,\n",
    "cabi_stations_mcn,\n",
    "cabi_stations_mcs,\n",
    "cabi_stations_wdc,\n",
    "cabi_docks_alx,\n",
    "cabi_docks_arl,\n",
    "cabi_docks_ffx,\n",
    "cabi_docks_mcn,\n",
    "cabi_docks_mcs,\n",
    "cabi_docks_wdc,\n",
    "cabi_stations_tot,\n",
    "cabi_docks_tot,\n",
    "cabi_dur_empty_wdc,\n",
    "cabi_dur_full_wdc,\n",
    "cabi_dur_empty_arl,\n",
    "cabi_dur_full_arl,\n",
    "cabi_dur_full_alx,\n",
    "cabi_dur_empty_alx,\n",
    "cabi_dur_empty_mcs,\n",
    "cabi_dur_full_mcs,\n",
    "cabi_dur_full_mcn,\n",
    "cabi_dur_empty_mcn,\n",
    "cabi_dur_full_ffx,\n",
    "cabi_dur_empty_ffx,\n",
    "cabi_dur_empty_tot,\n",
    "cabi_dur_full_tot,\n",
    "cabi_active_members_day_key,\n",
    "cabi_active_members_monthly,\n",
    "cabi_active_members_annual,\n",
    "cabi_trips_wdc_to_wdc,\n",
    "cabi_trips_wdc_to_wdc_casual\n",
    "from final_db\"\"\"\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "EXTRACT(DOY FROM date) as day_of_year,\n",
    "date,\n",
    "daylight_hours,\n",
    "apparenttemperaturehigh,\n",
    "cloudcover,\n",
    "humidity,\n",
    "precipaccumulation,\n",
    "precipintensitymax,\n",
    "precipprobability,\n",
    "rain,\n",
    "snow,\n",
    "visibility,\n",
    "windspeed,\n",
    "us_holiday,\n",
    "nats_single,\n",
    "nats_double,\n",
    "dc_bike_event,\n",
    "dc_pop,\n",
    "cabi_dur_empty_arl,\n",
    "cabi_dur_full_arl,\n",
    "cabi_dur_full_alx,\n",
    "cabi_dur_empty_alx,\n",
    "cabi_dur_empty_mcs,\n",
    "cabi_dur_full_mcs,\n",
    "cabi_dur_full_mcn,\n",
    "cabi_dur_empty_mcn,\n",
    "cabi_trips_wdc_to_wdc,\n",
    "cabi_trips_wdc_to_wdc_casual\n",
    "from final_db\"\"\"\n",
    "\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "df = pd.read_sql(query, con=conn)\n",
    "\n",
    "# Setting date to index for easier splitting\n",
    "df.set_index(df.date, drop=True, inplace=True)\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "print(\"We have {} instances and {} features\".format(*df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>50%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>day_of_year</th>\n",
       "      <td>2780.0</td>\n",
       "      <td>182.697</td>\n",
       "      <td>107.702</td>\n",
       "      <td>1.000</td>\n",
       "      <td>182.000</td>\n",
       "      <td>366.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daylight_hours</th>\n",
       "      <td>2780.0</td>\n",
       "      <td>12.077</td>\n",
       "      <td>2.021</td>\n",
       "      <td>9.000</td>\n",
       "      <td>12.000</td>\n",
       "      <td>15.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apparenttemperaturehigh</th>\n",
       "      <td>2780.0</td>\n",
       "      <td>64.306</td>\n",
       "      <td>20.594</td>\n",
       "      <td>2.240</td>\n",
       "      <td>65.890</td>\n",
       "      <td>113.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cloudcover</th>\n",
       "      <td>2780.0</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.270</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humidity</th>\n",
       "      <td>2780.0</td>\n",
       "      <td>0.669</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precipaccumulation</th>\n",
       "      <td>2780.0</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>21.427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precipintensitymax</th>\n",
       "      <td>2780.0</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precipprobability</th>\n",
       "      <td>2780.0</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rain</th>\n",
       "      <td>2780.0</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snow</th>\n",
       "      <td>2780.0</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visibility</th>\n",
       "      <td>2780.0</td>\n",
       "      <td>9.306</td>\n",
       "      <td>1.130</td>\n",
       "      <td>1.130</td>\n",
       "      <td>9.790</td>\n",
       "      <td>10.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>windspeed</th>\n",
       "      <td>2780.0</td>\n",
       "      <td>5.379</td>\n",
       "      <td>3.170</td>\n",
       "      <td>0.030</td>\n",
       "      <td>4.850</td>\n",
       "      <td>25.460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>us_holiday</th>\n",
       "      <td>2780.0</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nats_single</th>\n",
       "      <td>2780.0</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nats_double</th>\n",
       "      <td>2780.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dc_bike_event</th>\n",
       "      <td>2780.0</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dc_pop</th>\n",
       "      <td>2780.0</td>\n",
       "      <td>662465.171</td>\n",
       "      <td>26420.230</td>\n",
       "      <td>607733.153</td>\n",
       "      <td>665296.583</td>\n",
       "      <td>702021.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cabi_dur_empty_arl</th>\n",
       "      <td>2780.0</td>\n",
       "      <td>103321.117</td>\n",
       "      <td>132383.807</td>\n",
       "      <td>0.000</td>\n",
       "      <td>54818.500</td>\n",
       "      <td>1170040.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cabi_dur_full_arl</th>\n",
       "      <td>2780.0</td>\n",
       "      <td>43502.125</td>\n",
       "      <td>48157.214</td>\n",
       "      <td>0.000</td>\n",
       "      <td>31039.500</td>\n",
       "      <td>630049.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cabi_dur_full_alx</th>\n",
       "      <td>2780.0</td>\n",
       "      <td>10897.354</td>\n",
       "      <td>23990.773</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>311058.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cabi_dur_empty_alx</th>\n",
       "      <td>2780.0</td>\n",
       "      <td>6092.551</td>\n",
       "      <td>15606.603</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>388080.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cabi_dur_empty_mcs</th>\n",
       "      <td>2780.0</td>\n",
       "      <td>13949.235</td>\n",
       "      <td>40894.944</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>808844.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cabi_dur_full_mcs</th>\n",
       "      <td>2780.0</td>\n",
       "      <td>2318.766</td>\n",
       "      <td>8130.878</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>221578.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cabi_dur_full_mcn</th>\n",
       "      <td>2780.0</td>\n",
       "      <td>1401.324</td>\n",
       "      <td>10546.828</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>272821.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cabi_dur_empty_mcn</th>\n",
       "      <td>2780.0</td>\n",
       "      <td>2644.020</td>\n",
       "      <td>15048.476</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>324429.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cabi_trips_wdc_to_wdc</th>\n",
       "      <td>2780.0</td>\n",
       "      <td>6375.501</td>\n",
       "      <td>3185.075</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6240.000</td>\n",
       "      <td>16608.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cabi_trips_wdc_to_wdc_casual</th>\n",
       "      <td>2780.0</td>\n",
       "      <td>1395.860</td>\n",
       "      <td>1339.656</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>9130.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               count        mean         std         min  \\\n",
       "day_of_year                   2780.0     182.697     107.702       1.000   \n",
       "daylight_hours                2780.0      12.077       2.021       9.000   \n",
       "apparenttemperaturehigh       2780.0      64.306      20.594       2.240   \n",
       "cloudcover                    2780.0       0.340       0.244       0.000   \n",
       "humidity                      2780.0       0.669       0.137       0.210   \n",
       "precipaccumulation            2780.0       0.045       0.527       0.000   \n",
       "precipintensitymax            2780.0       0.029       0.072       0.000   \n",
       "precipprobability             2780.0       0.282       0.373       0.000   \n",
       "rain                          2780.0       0.454       0.498       0.000   \n",
       "snow                          2780.0       0.040       0.196       0.000   \n",
       "visibility                    2780.0       9.306       1.130       1.130   \n",
       "windspeed                     2780.0       5.379       3.170       0.030   \n",
       "us_holiday                    2780.0       0.031       0.173       0.000   \n",
       "nats_single                   2780.0       0.200       0.400       0.000   \n",
       "nats_double                   2780.0       0.006       0.078       0.000   \n",
       "dc_bike_event                 2780.0       0.009       0.094       0.000   \n",
       "dc_pop                        2780.0  662465.171   26420.230  607733.153   \n",
       "cabi_dur_empty_arl            2780.0  103321.117  132383.807       0.000   \n",
       "cabi_dur_full_arl             2780.0   43502.125   48157.214       0.000   \n",
       "cabi_dur_full_alx             2780.0   10897.354   23990.773       0.000   \n",
       "cabi_dur_empty_alx            2780.0    6092.551   15606.603       0.000   \n",
       "cabi_dur_empty_mcs            2780.0   13949.235   40894.944       0.000   \n",
       "cabi_dur_full_mcs             2780.0    2318.766    8130.878       0.000   \n",
       "cabi_dur_full_mcn             2780.0    1401.324   10546.828       0.000   \n",
       "cabi_dur_empty_mcn            2780.0    2644.020   15048.476       0.000   \n",
       "cabi_trips_wdc_to_wdc         2780.0    6375.501    3185.075       0.000   \n",
       "cabi_trips_wdc_to_wdc_casual  2780.0    1395.860    1339.656       0.000   \n",
       "\n",
       "                                     50%          max  \n",
       "day_of_year                      182.000      366.000  \n",
       "daylight_hours                    12.000       15.000  \n",
       "apparenttemperaturehigh           65.890      113.670  \n",
       "cloudcover                         0.270        1.000  \n",
       "humidity                           0.670        0.970  \n",
       "precipaccumulation                 0.000       21.427  \n",
       "precipintensitymax                 0.001        1.185  \n",
       "precipprobability                  0.000        1.000  \n",
       "rain                               0.000        1.000  \n",
       "snow                               0.000        1.000  \n",
       "visibility                         9.790       10.000  \n",
       "windspeed                          4.850       25.460  \n",
       "us_holiday                         0.000        1.000  \n",
       "nats_single                        0.000        1.000  \n",
       "nats_double                        0.000        1.000  \n",
       "dc_bike_event                      0.000        1.000  \n",
       "dc_pop                        665296.583   702021.562  \n",
       "cabi_dur_empty_arl             54818.500  1170040.000  \n",
       "cabi_dur_full_arl              31039.500   630049.000  \n",
       "cabi_dur_full_alx                  0.000   311058.000  \n",
       "cabi_dur_empty_alx                 0.000   388080.000  \n",
       "cabi_dur_empty_mcs                 0.000   808844.000  \n",
       "cabi_dur_full_mcs                  0.000   221578.000  \n",
       "cabi_dur_full_mcn                  0.000   272821.000  \n",
       "cabi_dur_empty_mcn                 0.000   324429.000  \n",
       "cabi_trips_wdc_to_wdc           6240.000    16608.000  \n",
       "cabi_trips_wdc_to_wdc_casual    1000.000     9130.000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics\n",
    "\n",
    "df.describe(percentiles=[.5]).round(3).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 feature pairs with pairwise correlation above 0.75\n",
      "cabi_trips_wdc_to_wdc and cabi_trips_wdc_to_wdc_casual = 0.770\n"
     ]
    }
   ],
   "source": [
    "def print_highly_correlated(df, features, threshold=0.75):\n",
    "    \"\"\" \n",
    "    Prints highly correlated feature pairs in df.\n",
    "    \"\"\"\n",
    "    corr_df = df[features].corr()\n",
    "    # Select pairs above threshold\n",
    "    correlated_features = np.where(np.abs(corr_df) > threshold)\n",
    "    # Avoid duplication\n",
    "    correlated_features = [(corr_df.iloc[x,y], x, y) for x, y in zip(*correlated_features) if x != y and x < y]\n",
    "    # Sort by abs(correlation)\n",
    "    s_corr_list = sorted(correlated_features, key=lambda x: -abs(x[0]))\n",
    "    print(\"There are {} feature pairs with pairwise correlation above {}\".format(len(s_corr_list), threshold))\n",
    "    for v, i, j in s_corr_list:\n",
    "        cols = df[features].columns\n",
    "        print(\"{} and {} = {:0.3f}\".format(corr_df.index[i], corr_df.columns[j], v))\n",
    "        \n",
    "print_highly_correlated(df, df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode day_of_year as cyclical\n",
    "df['sin_day_of_year'] = np.sin(2*np.pi*df.day_of_year/365)\n",
    "df['cos_day_of_year'] = np.cos(2*np.pi*df.day_of_year/365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(100).plot.scatter('sin_day_of_year','cos_day_of_year').set_aspect('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Split into Xtrain, Xtest, ytrain, ytest based on date\n",
    "  * Training dates = 2013-01-01 to 2016-12-31\n",
    "  * Test dates = 2017-01-01 to 2017-09-08\n",
    "  * New data (coincides with beginning of dockless pilot) = 2017-09-09 to present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1461, 30) (251, 30)\n",
      "0.853 percent of the data is in the training set and 0.147 percent is in the test set\n"
     ]
    }
   ],
   "source": [
    "# Train test split\n",
    "# This can be tweaked, but we use 5-fold cross-validation to pick the model so that shouldn't change\n",
    "\n",
    "train = df.loc['2013-01-01':'2016-12-31']\n",
    "test = df.loc['2017-01-01':'2017-09-08']\n",
    "print(train.shape, test.shape)\n",
    "\n",
    "tr = train.shape[0]\n",
    "te = test.shape[0]\n",
    "trpct = tr/(tr+te)\n",
    "tepct = te/(tr+te)\n",
    "\n",
    "print(\"{:0.3f} percent of the data is in the training set and {:0.3f} percent is in the test set\".format(trpct, tepct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1461, 26) (1461,) (251, 26) (251,)\n"
     ]
    }
   ],
   "source": [
    "# Specify columns to keep and drop for X and y\n",
    "drop_cols = ['date', 'day_of_year']\n",
    "y_cols = ['cabi_trips_wdc_to_wdc', 'cabi_trips_wdc_to_wdc_casual']\n",
    "\n",
    "feature_cols = [col for col in df.columns if (col not in y_cols) & (col not in drop_cols)]\n",
    "\n",
    "# X y split\n",
    "Xtrain_raw = train[feature_cols]\n",
    "\n",
    "# Our target variable here is all DC to DC trips\n",
    "ytrain = train[y_cols[0]]\n",
    "Xtest_raw = test[feature_cols]\n",
    "ytest = test[y_cols[0]]\n",
    "print(Xtrain_raw.shape, ytrain.shape, Xtest_raw.shape, ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preprocessing\n",
    "\n",
    "We want to use PolynomialFeatures and StandardScaler in a Pipeline, but we only want to scale continuous features.\n",
    "\n",
    "Here, I do the polynomial transformation first and then feed it through a pipeline because I wasn't able to get it all working in one pipeline.\n",
    "\n",
    "* Use PolynomialFeatures to create quadratic and interaction terms\n",
    "  * Convert back to DataFrame\n",
    "  * Drop redundant variables\n",
    "* Use Pipeline and FeatureUnion to selectively scale/ignore certain variables\n",
    "* Fit and transform using pipeline to get final Xtrain and Xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and custom classes\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, MinMaxScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class Columns(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" \n",
    "    This is a custom transformer for splitting the data into subsets for FeatureUnion.\n",
    "    \"\"\"\n",
    "    def __init__(self, names=None):\n",
    "        self.names = names\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.names]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1461, 26) (251, 26)\n"
     ]
    }
   ],
   "source": [
    "# Use PolynomialFeatures to create quadratic and interaction terms\n",
    "# Should ultimately be part of a Pipeline, but I had issues because \n",
    "# PF returns an array and Columns requires a df\n",
    "\n",
    "pf = PolynomialFeatures(1, include_bias=False)\n",
    "\n",
    "Xtrain_pf_array = pf.fit_transform(Xtrain_raw)\n",
    "Xtest_pf_array = pf.transform(Xtest_raw)\n",
    "\n",
    "# Get feature names \n",
    "Xtrain_cols = pf.get_feature_names(Xtrain_raw.columns)\n",
    "\n",
    "# Convert arrays to dfs with the new pf column names\n",
    "Xtrain_pf = pd.DataFrame(Xtrain_pf_array, columns=Xtrain_cols)\n",
    "Xtest_pf = pd.DataFrame(Xtest_pf_array, columns=Xtrain_cols)\n",
    "\n",
    "print(Xtrain_pf.shape, Xtest_pf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rain', 'snow', 'us_holiday', 'nats_single', 'nats_double', 'dc_bike_event']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A lot of these variables are redundant, especially squared dummy variables\n",
    "# All of these variables listed next are 'binary' but only some are meaningful\n",
    "\n",
    "bin_vars = [col for col in Xtrain_pf.columns if Xtrain_pf[col].nunique() == 2]\n",
    "bin_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1461, 26) (251, 26)\n"
     ]
    }
   ],
   "source": [
    "# Dropping squared dummies and nonsensical interaction terms\n",
    "# This part can be expanded. There's a lot of noise after PF\n",
    "\n",
    "to_drop = [\n",
    "    'rain^2', 'snow^2', 'us_holiday^2', 'nats_single^2', 'nats_double^2', \n",
    "    'dc_bike_event^2', 'sin_day_of_year^2', 'cos_day_of_year^2',\n",
    "    'sin_day_of_year cos_day_of_year'\n",
    "]\n",
    "'''\n",
    "Xtrain_pf2 = Xtrain_pf.drop(labels=to_drop, axis=1)\n",
    "Xtest_pf2 = Xtest_pf.drop(labels=to_drop, axis=1)\n",
    "'''\n",
    "Xtrain_pf2 = Xtrain_pf.copy()\n",
    "Xtest_pf2 = Xtest_pf.copy()\n",
    "\n",
    "print(Xtrain_pf2.shape, Xtest_pf2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>daylight_hours</th>\n",
       "      <th>apparenttemperaturehigh</th>\n",
       "      <th>cloudcover</th>\n",
       "      <th>humidity</th>\n",
       "      <th>precipaccumulation</th>\n",
       "      <th>precipintensitymax</th>\n",
       "      <th>precipprobability</th>\n",
       "      <th>rain</th>\n",
       "      <th>snow</th>\n",
       "      <th>visibility</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>us_holiday</th>\n",
       "      <th>nats_single</th>\n",
       "      <th>nats_double</th>\n",
       "      <th>dc_bike_event</th>\n",
       "      <th>dc_pop</th>\n",
       "      <th>cabi_dur_empty_arl</th>\n",
       "      <th>cabi_dur_full_arl</th>\n",
       "      <th>cabi_dur_full_alx</th>\n",
       "      <th>cabi_dur_empty_alx</th>\n",
       "      <th>cabi_dur_empty_mcs</th>\n",
       "      <th>cabi_dur_full_mcs</th>\n",
       "      <th>cabi_dur_full_mcn</th>\n",
       "      <th>cabi_dur_empty_mcn</th>\n",
       "      <th>sin_day_of_year</th>\n",
       "      <th>cos_day_of_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>41.12</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>4.91</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>646400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8635.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>30.18</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>6.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>646400.0</td>\n",
       "      <td>39580.0</td>\n",
       "      <td>14297.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034422</td>\n",
       "      <td>0.999407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>32.65</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>646400.0</td>\n",
       "      <td>9426.0</td>\n",
       "      <td>12830.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051620</td>\n",
       "      <td>0.998667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>37.60</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.99</td>\n",
       "      <td>6.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>646400.0</td>\n",
       "      <td>27949.0</td>\n",
       "      <td>40820.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068802</td>\n",
       "      <td>0.997630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>43.83</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.98</td>\n",
       "      <td>2.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>646400.0</td>\n",
       "      <td>13432.0</td>\n",
       "      <td>22196.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085965</td>\n",
       "      <td>0.996298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   daylight_hours  apparenttemperaturehigh  cloudcover  humidity  \\\n",
       "0             9.0                    41.12        0.82      0.61   \n",
       "1             9.0                    30.18        0.49      0.54   \n",
       "2             9.0                    32.65        0.30      0.59   \n",
       "3            10.0                    37.60        0.16      0.55   \n",
       "4            10.0                    43.83        0.21      0.55   \n",
       "\n",
       "   precipaccumulation  precipintensitymax  precipprobability  rain  snow  \\\n",
       "0                 0.0                 0.0                0.0   0.0   0.0   \n",
       "1                 0.0                 0.0                0.0   0.0   0.0   \n",
       "2                 0.0                 0.0                0.0   0.0   0.0   \n",
       "3                 0.0                 0.0                0.0   0.0   0.0   \n",
       "4                 0.0                 0.0                0.0   0.0   0.0   \n",
       "\n",
       "   visibility  windspeed  us_holiday  nats_single  nats_double  dc_bike_event  \\\n",
       "0       10.00       4.91         1.0          0.0          0.0            0.0   \n",
       "1       10.00       6.75         0.0          0.0          0.0            0.0   \n",
       "2       10.00       1.29         0.0          0.0          0.0            0.0   \n",
       "3        9.99       6.83         0.0          0.0          0.0            0.0   \n",
       "4        9.98       2.92         0.0          0.0          0.0            0.0   \n",
       "\n",
       "     dc_pop  cabi_dur_empty_arl  cabi_dur_full_arl  cabi_dur_full_alx  \\\n",
       "0  646400.0                 0.0             8635.0                0.0   \n",
       "1  646400.0             39580.0            14297.0                0.0   \n",
       "2  646400.0              9426.0            12830.0                0.0   \n",
       "3  646400.0             27949.0            40820.0                0.0   \n",
       "4  646400.0             13432.0            22196.0                0.0   \n",
       "\n",
       "   cabi_dur_empty_alx  cabi_dur_empty_mcs  cabi_dur_full_mcs  \\\n",
       "0                 0.0                 0.0                0.0   \n",
       "1                 0.0                 0.0                0.0   \n",
       "2                 0.0                 0.0                0.0   \n",
       "3                 0.0                 0.0                0.0   \n",
       "4                 0.0                 0.0                0.0   \n",
       "\n",
       "   cabi_dur_full_mcn  cabi_dur_empty_mcn  sin_day_of_year  cos_day_of_year  \n",
       "0                0.0                 0.0         0.017213         0.999852  \n",
       "1                0.0                 0.0         0.034422         0.999407  \n",
       "2                0.0                 0.0         0.051620         0.998667  \n",
       "3                0.0                 0.0         0.068802         0.997630  \n",
       "4                0.0                 0.0         0.085965         0.996298  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_pf2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining binary and continuous variables\n",
    "# We have normal 0,1 binary variables, binary variables outside 0,1 that were created by PF, and continuous variables\n",
    "# We want to ignore the 0,1s, MinMaxScale the non 0,1 binary variables, and StandardScale the continuous variables\n",
    "\n",
    "binary = ['rain', 'snow', 'us_holiday', 'nats_single', 'nats_double', 'dc_bike_event']\n",
    "cont = [col for col in Xtrain_pf2.columns if (col not in binary)]\n",
    "\n",
    "# FeatureUnion in our pipeline shifts the ordering of the variables so we need to save the ordering here\n",
    "cols = binary + cont\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('binarypf', Pipeline([\n",
    "            ('binpfcols', Columns(names=binary)),\n",
    "            ('minmax', MinMaxScaler())\n",
    "        ])),\n",
    "        ('continuous', Pipeline([\n",
    "            ('contcols', Columns(names=cont)),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]))\n",
    "    ]))   \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1461, 26) (251, 26)\n"
     ]
    }
   ],
   "source": [
    "# Fit and transform to create our final Xtrain and Xtest\n",
    "\n",
    "pipeline.fit(Xtrain_pf2)\n",
    "Xtrain_scaled = pipeline.transform(Xtrain_pf2)\n",
    "Xtest_scaled = pipeline.transform(Xtest_pf2)\n",
    "\n",
    "# Put everything back into dfs\n",
    "Xtrain = pd.DataFrame(Xtrain_scaled, columns=cols)\n",
    "Xtest = pd.DataFrame(Xtest_scaled, columns=cols)\n",
    "print(Xtrain.shape, Xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>50%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rain</th>\n",
       "      <td>1461.0</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snow</th>\n",
       "      <td>1461.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>us_holiday</th>\n",
       "      <td>1461.0</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nats_single</th>\n",
       "      <td>1461.0</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nats_double</th>\n",
       "      <td>1461.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dc_bike_event</th>\n",
       "      <td>1461.0</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daylight_hours</th>\n",
       "      <td>1461.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-1.565</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>1.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apparenttemperaturehigh</th>\n",
       "      <td>1461.0</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-2.975</td>\n",
       "      <td>0.098</td>\n",
       "      <td>2.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cloudcover</th>\n",
       "      <td>1461.0</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-1.296</td>\n",
       "      <td>-0.330</td>\n",
       "      <td>3.304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humidity</th>\n",
       "      <td>1461.0</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-2.774</td>\n",
       "      <td>0.072</td>\n",
       "      <td>2.188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precipaccumulation</th>\n",
       "      <td>1461.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.093</td>\n",
       "      <td>-0.093</td>\n",
       "      <td>31.534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precipintensitymax</th>\n",
       "      <td>1461.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.402</td>\n",
       "      <td>-0.390</td>\n",
       "      <td>12.790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precipprobability</th>\n",
       "      <td>1461.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.754</td>\n",
       "      <td>-0.754</td>\n",
       "      <td>1.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visibility</th>\n",
       "      <td>1461.0</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-6.909</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>windspeed</th>\n",
       "      <td>1461.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-1.686</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>4.539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dc_pop</th>\n",
       "      <td>1461.0</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-1.851</td>\n",
       "      <td>0.134</td>\n",
       "      <td>1.474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cabi_dur_empty_arl</th>\n",
       "      <td>1461.0</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-1.032</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>4.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cabi_dur_full_arl</th>\n",
       "      <td>1461.0</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-1.046</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>14.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cabi_dur_full_alx</th>\n",
       "      <td>1461.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.646</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>10.966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cabi_dur_empty_alx</th>\n",
       "      <td>1461.0</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.529</td>\n",
       "      <td>-0.529</td>\n",
       "      <td>10.915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cabi_dur_empty_mcs</th>\n",
       "      <td>1461.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.503</td>\n",
       "      <td>-0.503</td>\n",
       "      <td>10.883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cabi_dur_full_mcs</th>\n",
       "      <td>1461.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>28.217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cabi_dur_full_mcn</th>\n",
       "      <td>1461.0</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>33.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cabi_dur_empty_mcn</th>\n",
       "      <td>1461.0</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>31.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sin_day_of_year</th>\n",
       "      <td>1461.0</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-1.415</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>1.415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cos_day_of_year</th>\n",
       "      <td>1461.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-1.415</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1.413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          count   mean    std    min    50%     max\n",
       "rain                     1461.0  0.449  0.498  0.000  0.000   1.000\n",
       "snow                     1461.0  0.047  0.211  0.000  0.000   1.000\n",
       "us_holiday               1461.0  0.029  0.167  0.000  0.000   1.000\n",
       "nats_single              1461.0  0.211  0.408  0.000  0.000   1.000\n",
       "nats_double              1461.0  0.005  0.074  0.000  0.000   1.000\n",
       "dc_bike_event            1461.0  0.012  0.110  0.000  0.000   1.000\n",
       "daylight_hours           1461.0  0.000  1.000 -1.565 -0.090   1.385\n",
       "apparenttemperaturehigh  1461.0 -0.000  1.000 -2.975  0.098   2.038\n",
       "cloudcover               1461.0 -0.000  1.000 -1.296 -0.330   3.304\n",
       "humidity                 1461.0 -0.000  1.000 -2.774  0.072   2.188\n",
       "precipaccumulation       1461.0  0.000  1.000 -0.093 -0.093  31.534\n",
       "precipintensitymax       1461.0  0.000  1.000 -0.402 -0.390  12.790\n",
       "precipprobability        1461.0  0.000  1.000 -0.754 -0.754   1.957\n",
       "visibility               1461.0 -0.000  1.000 -6.909  0.426   0.604\n",
       "windspeed                1461.0  0.000  1.000 -1.686 -0.185   4.539\n",
       "dc_pop                   1461.0 -0.000  1.000 -1.851  0.134   1.474\n",
       "cabi_dur_empty_arl       1461.0 -0.000  1.000 -1.032 -0.250   4.663\n",
       "cabi_dur_full_arl        1461.0 -0.000  1.000 -1.046 -0.253  14.056\n",
       "cabi_dur_full_alx        1461.0  0.000  1.000 -0.646 -0.428  10.966\n",
       "cabi_dur_empty_alx       1461.0 -0.000  1.000 -0.529 -0.529  10.915\n",
       "cabi_dur_empty_mcs       1461.0  0.000  1.000 -0.503 -0.503  10.883\n",
       "cabi_dur_full_mcs        1461.0  0.000  1.000 -0.265 -0.265  28.217\n",
       "cabi_dur_full_mcn        1461.0 -0.000  1.000 -0.078 -0.078  33.857\n",
       "cabi_dur_empty_mcn       1461.0 -0.000  1.000 -0.144 -0.144  31.363\n",
       "sin_day_of_year          1461.0 -0.000  1.000 -1.415 -0.000   1.415\n",
       "cos_day_of_year          1461.0  0.000  1.000 -1.415  0.005   1.413"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.describe(percentiles=[.5]).round(3).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1712, 26) (1712,)\n"
     ]
    }
   ],
   "source": [
    "# Appending train and test to get full dataset for cross-validation\n",
    "\n",
    "Xfull = Xtrain.append(Xtest)\n",
    "yfull = ytrain.append(ytest)\n",
    "print(Xfull.shape, yfull.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import median_absolute_error as medae\n",
    "from sklearn.metrics import explained_variance_score as evs\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def score_model(model, alpha=False):\n",
    "    \"\"\" \n",
    "    Fits a model using the training set, predicts using the test set, and then calculates \n",
    "    and reports goodness of fit metrics and alpha if specified and available.\n",
    "    \"\"\"\n",
    "    model.fit(Xtrain, ytrain)\n",
    "    yhat = model.predict(Xtest)\n",
    "    r2 = r2_score(ytest, yhat)\n",
    "    me = mse(ytest, yhat)\n",
    "    ae = mae(ytest, yhat)\n",
    "    mede = medae(ytest, yhat)\n",
    "    ev = evs(ytest, yhat)\n",
    "    \n",
    "    if alpha == True:\n",
    "        print(\"Results from {}: \\nr2={:0.3f} \\nMSE={:0.3f} \\\n",
    "              \\nMAE={:0.3f} \\nMEDAE={:0.3f} \\nEVS={:0.3f} \\nalpha={:0.3f}\".format(model, r2, me, \n",
    "                                                                                  ae, mede, ev, model.alpha_))\n",
    "    else:\n",
    "        print(\"Results from {}: \\nr2={:0.3f} \\nMSE={:0.3f} \\\n",
    "              \\nMAE={:0.3f} \\nMEDAE={:0.3f} \\nEVS={:0.3f}\".format(model, r2, me, ae, mede, ev))\n",
    "\n",
    "def cv_score(model, cv=5):\n",
    "    \"\"\"\n",
    "    Evaluates a model by 5-fold cross-validation and prints mean and 2*stdev of scores.\n",
    "    Shuffles before cross-validation but sets random_state=7 for reproducibility.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=cv, shuffle=True, random_state=7)\n",
    "    scores = cross_val_score(model, Xfull, yfull, cv=kf)\n",
    "    print(scores)\n",
    "    print(\"Accuracy: {:0.3f} (+/- {:0.3f})\".format(scores.mean(), scores.std() * 2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results from ElasticNetCV(alphas=array([  1.     ,   1.01867, ...,  98.16753, 100.     ]),\n",
      "       copy_X=True, cv=None, eps=0.001, fit_intercept=True,\n",
      "       l1_ratio=[0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1], max_iter=1000,\n",
      "       n_alphas=100, n_jobs=1, normalize=False, positive=False,\n",
      "       precompute='auto', random_state=None, selection='cyclic',\n",
      "       tol=0.0001, verbose=0): \n",
      "r2=0.726 \n",
      "MSE=2609251.060               \n",
      "MAE=1225.785 \n",
      "MEDAE=962.899 \n",
      "EVS=0.731 \n",
      "alpha=51.386\n",
      "L1 ratio= 1.0\n",
      "This cell took 0.02 minutes to run\n"
     ]
    }
   ],
   "source": [
    "'''Elastic Net'''\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "\n",
    "t = time.perf_counter()\n",
    "\n",
    "# Alphas to search over\n",
    "# Our alpha is usually in the low double digits\n",
    "# This sets our search space to 250 steps between 10^0=1 and 10^2=100\n",
    "alphas = np.logspace(0, 2, 250)\n",
    "\n",
    "# Suggested l1_ratio from docs\n",
    "l1_ratio = [.1, .5, .7, .9, .95, .99, 1]\n",
    "\n",
    "en = ElasticNetCV(l1_ratio=l1_ratio, alphas=alphas, fit_intercept=True, normalize=False)\n",
    "\n",
    "score_model(en, alpha=True)\n",
    "print(\"L1 ratio=\",en.l1_ratio_)\n",
    "\n",
    "elapsed_time = (time.perf_counter() - t)/60\n",
    "print(\"This cell took {:0.2f} minutes to run\".format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results from LassoCV(alphas=array([  1.     ,   1.01867, ...,  98.16753, 100.     ]),\n",
      "    copy_X=True, cv=None, eps=0.001, fit_intercept=True, max_iter=1000,\n",
      "    n_alphas=250, n_jobs=1, normalize=False, positive=False,\n",
      "    precompute='auto', random_state=None, selection='cyclic', tol=0.0001,\n",
      "    verbose=False): \n",
      "r2=0.726 \n",
      "MSE=2609251.060               \n",
      "MAE=1225.785 \n",
      "MEDAE=962.899 \n",
      "EVS=0.731 \n",
      "alpha=51.386\n",
      "This cell took 0.00 minutes to run\n"
     ]
    }
   ],
   "source": [
    "'''Lasso'''\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "t = time.perf_counter()\n",
    "\n",
    "lasso = LassoCV(alphas=alphas, n_alphas=250, fit_intercept=True, normalize=False)\n",
    "score_model(lasso, alpha=True)\n",
    "\n",
    "elapsed_time = (time.perf_counter() - t)/60\n",
    "print(\"This cell took {:0.2f} minutes to run\".format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso chooses 16 variables\n",
      "                                   0       sorted\n",
      "apparenttemperaturehigh  1203.374249  1203.374249\n",
      "cabi_dur_empty_arl        774.635475   774.635475\n",
      "cos_day_of_year          -457.807402   457.807402\n",
      "precipprobability        -330.546369   330.546369\n",
      "cabi_dur_full_alx         173.288444   173.288444\n",
      "visibility                167.064765   167.064765\n",
      "precipintensitymax       -158.145112   158.145112\n",
      "dc_pop                    155.483506   155.483506\n",
      "humidity                 -142.075967   142.075967\n",
      "cabi_dur_full_arl         131.543575   131.543575\n",
      "cabi_dur_full_mcn         -79.744154    79.744154\n",
      "sin_day_of_year           -47.390930    47.390930\n",
      "cloudcover                -40.071896    40.071896\n",
      "precipaccumulation        -37.541709    37.541709\n",
      "cabi_dur_empty_mcn         -5.760903     5.760903\n",
      "daylight_hours              0.460229     0.460229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\Sebastian\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# Which variables were selected?\n",
    "\n",
    "# Put coefficients and variable names in df\n",
    "lassodf = pd.DataFrame(lasso.coef_, index=Xtrain.columns)\n",
    "\n",
    "# Select nonzeros\n",
    "results = lassodf[(lassodf.T != 0).any()]\n",
    "\n",
    "# Sort by magnitude\n",
    "results['sorted'] = results[0].abs()\n",
    "results.sort_values(by='sorted', inplace=True, ascending=False)\n",
    "\n",
    "print(\"Lasso chooses {} variables\".format(len(results)))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results from RidgeCV(alphas=array([  1.     ,   1.01867, ...,  98.16753, 100.     ]),\n",
      "    cv=None, fit_intercept=True, gcv_mode=None, normalize=False,\n",
      "    scoring=None, store_cv_values=False): \n",
      "r2=0.702 \n",
      "MSE=2838285.288               \n",
      "MAE=1282.486 \n",
      "MEDAE=1028.311 \n",
      "EVS=0.712 \n",
      "alpha=4.557\n",
      "[0.83850586 0.8310202  0.80515251 0.84067033 0.83731995]\n",
      "Accuracy: 0.831 (+/- 0.026)\n",
      "This cell took 0.02 minutes to run\n"
     ]
    }
   ],
   "source": [
    "'''Ridge'''\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "t = time.perf_counter()\n",
    "\n",
    "rr = RidgeCV(alphas=alphas, fit_intercept=True, normalize=False)\n",
    "\n",
    "score_model(rr, alpha=True)\n",
    "\n",
    "cv_score(rr)\n",
    "\n",
    "elapsed_time = (time.perf_counter() - t)/60\n",
    "print(\"This cell took {:0.2f} minutes to run\".format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results from RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False): \n",
      "r2=0.834 \n",
      "MSE=1577176.000               \n",
      "MAE=1004.814 \n",
      "MEDAE=827.600 \n",
      "EVS=0.848\n",
      "[0.89521847 0.89681913 0.86991449 0.89920209 0.90777976]\n",
      "Accuracy: 0.894 (+/- 0.025)\n",
      "This cell took 0.01 minutes to run\n"
     ]
    }
   ],
   "source": [
    "'''RF'''\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "t = time.perf_counter()\n",
    "\n",
    "rf = RandomForestRegressor() \n",
    "score_model(rf)\n",
    "\n",
    "cv_score(rf)\n",
    "\n",
    "elapsed_time = (time.perf_counter() - t)/60\n",
    "print(\"This cell took {:0.2f} minutes to run\".format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82588065 0.81899845 0.80350681 0.82744188 0.8323027 ]\n",
      "Accuracy: 0.822 (+/- 0.020)\n",
      "This cell took 0.01 minutes to run\n"
     ]
    }
   ],
   "source": [
    "t = time.perf_counter()\n",
    "\n",
    "cv_score(lasso)\n",
    "\n",
    "elapsed_time = (time.perf_counter() - t)/60\n",
    "print(\"This cell took {:0.2f} minutes to run\".format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook took 0.12 minutes to run\n"
     ]
    }
   ],
   "source": [
    "end_time = (time.perf_counter() - start_time)/60\n",
    "print(\"This notebook took {:0.2f} minutes to run\".format(end_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do:\n",
    "* No polynomials, 3 polynomials\n",
    "* How to interpret the coefficients?\n",
    "* Modify train/test split size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
